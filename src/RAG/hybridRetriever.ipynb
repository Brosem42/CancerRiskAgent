{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00de5a0",
   "metadata": {},
   "source": [
    "# Safely Store ENV variables for Gemini, Chroma DB connection, and vector embeddings\n",
    "### Additional techniques: cleared memory of any existing variables to avoid accidental exposure. Performed due to significant security risk of exposing PII and PHI for healthcare data.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4be341c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTALLS\n",
    "#! pip install rank-bm25\n",
    "#! pip install langchain-classic rank_bm25 langchain-community\n",
    "#! pip install -U langchain-google-vertexai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "58778aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "# # load dotenv + imports for retriever tool\n",
    "from getpass import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma \n",
    "from langchain.tools import tool\n",
    "import langchainhub as hub\n",
    "import chromadb\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings #type:ignore\n",
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "# from langchain_community.retrievers import BM25Retriever\n",
    "# from langchain_core.runnables import RunnableLambda, RunnableSequence, RunnableMap, RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.runnables import Runnable\n",
    "# from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "# from llama_index.core import StorageContext, VectorStoreIndex, Document\n",
    "# from llama_index.retrievers.bm25 import BM25Retriever\n",
    "# from llama_index.core.retrievers import QueryFusionRetriever\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43dd47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv(\"CHROMA_API_KEY\") or getpass(\"Paste CHROMA_API_KEY: \")\n",
    "tenant = os.getenv(\"CHROMA_TENANT\") or input(\"Enter CHROMA_TENANT: \")\n",
    "database = os.getenv(\"CHROMA_DATABASE\") or input(\"Enter CHROMA_DATABASE: \")\n",
    "gemini_key = os.getenv(\"GEMINI_API_KEY\") or getpass(\"Enter GEMINI_API_KEY: \")\n",
    "vertex_ai_key = os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\") or getpass(\"Enter GOOGLE_APPLICATION_CREDENTIALS: \")\n",
    "openAI_api_key = os.getenv(\"OPENAI_API_KEY\") or getpass(\"Enter OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = gemini_key\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = vertex_ai_key\n",
    "os.environ[\"OPENAI_API_KEY\"] = openAI_api_key\n",
    "\n",
    "# Load environment variables from chromaDB --CloudClient\n",
    "client = chromadb.CloudClient(\n",
    "    api_key=api_key, \n",
    "    tenant=tenant, \n",
    "    database=database)\n",
    "\n",
    "#importing Gemini for embedding, checking dimensions for retriever\n",
    "model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "\n",
    "embeddings= GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "embeddings.embed_query(\"NG12 Cancer Risk Assessor guidelines\")\n",
    "\n",
    "#vertexai init\n",
    "embedding = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"gemini-embedding-001\",\n",
    "    project=\"CancerRiskAgent\",\n",
    "    vertexai=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e2be3",
   "metadata": {},
   "source": [
    "# **Challenges + Mitigation strategies for Performing Vector Search:**\n",
    "---\n",
    "#### **Tradeoffs:**\n",
    "- Originally, my plan was to use the same framework for both retrievers, then fetch the data from my vector store in chroma. However, I found that my BM25 retriever simply would not return any data for either framework--langchain or llamaindex. Later on, I found out that due to how the BM25-Retriever architecture is built, the keyword search library needs access to pull data from **raw text nodes**. This does not align with my current Chroma vector store DB architecture, which is built **with stored embeddings--not original text**. Hence, why orginally no data was being returned in my prior iteration. \n",
    "\n",
    "#### **How I solved for this/Why I chose this method?:**\n",
    "To mitigate for this, I decided to change my framework and use llamaindex for BM25/lexical retriever; it provides a much more seamless integration with the Chroma vector store architecture. Then, I used llamaindex to pass my list of nodes directly to the BM25 retriever, which solved the short-term problem.\n",
    "\n",
    "#### **Improvement with Llama_Index:**\n",
    "- Use raw text nodes for BM25 retrieval to ensure compatibility with the keyword search library\n",
    "- Implement response enhancement by providing additional context or *page_content* for my document queries.\n",
    "\n",
    "---\n",
    "\n",
    "## **Pitfall/Tradeoffs with my original approach:**\n",
    "While attempting to test the combination of langchain and llamaIndex for different retrievers, I came across multiple problems. The main issue, my database and embeddings are in ChromaDB. The issue arises when performing a hybrid retrieval--where you **combine both a semantic, dense retriever and a lexical, keyword precise retriever**. The **root problem stemmed from BM25's architecture**. Semantic retriever seamlessy integrates with my dB because it uses the **vector_store from Chroma**. My BM25 does not integrate well because it **must pass the queried Document objects as nodes**--**something that can only be performed with VectorStoreIndex in LlamaIndex**. Being that Chroma is very langchain dependent and VectorStoreIndex is LlamaIndex dependant, combining these two very different methods would result in uneccessary overhead. I also had to factor in the limited constraint of having to use Gemini 1.5 with VertexAI embeddings, which is a closed-solution.\n",
    "\n",
    "- If I had to start over, to successfully integrate a hybrid retrieval RAG, I would have used either **OpenAI embeddings, ChatGPT4o, and ChromaDB** to still keep the closed-source solution in production. \n",
    "\n",
    "- If building proof of concept locally, I would use **FAISS for my vector store** + replace my **model with Gemma from HuggingFace.** for a more open source solution.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45313c8",
   "metadata": {},
   "source": [
    "# **Final RAG Approach:**\n",
    "---\n",
    "\n",
    "## My main consideration...**How can I pivot without losing retrieval quality?****\n",
    "My plan is to move to a more powerful approach by performing accurate similarity search with my **vector_store in ChromaDb** as my retriever in langchain. This is done to obtain exact matches with the potential of ingesting large documents via **Approximate Nearest Neighbors (ANN) algorithm built-in to ChromaDB**. Then, I will apply **Maximum Marginal Relevance(MMR)**. It's a great pivot from my prior solution. I'm able to optimize for balance between **relevance and diversity in a faster time complexity**. In a live healthcare environment, my agent would come in contact with multiple provider oppinions. In order to accurately generate responses that mimic live production, I would need to compensate for scaling this factor later on. Hence, whyn I chose this method.\n",
    "**Benefits:**\n",
    "- Prioritizes relevance and diversity during retrieval\n",
    "- Compensates for random spikes during data ingestion\n",
    "- Balances exploration with exploitation\n",
    "- Ensures my retrieved documents are distinct from each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb84c8",
   "metadata": {},
   "source": [
    "# **Creating VectorStore for LangChain + Enhancing Responses by Verifying Context Retrieved: How I Improved Generator Output:** \n",
    "---\n",
    "### Used response enhancement as a guideline for the model to follow when verifying retrieved content, building a better **knowledge base engine** for my agent to fetch. This system design technique results in a more enhanced **RAG performance + quality**. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding response enhancement for generated outputs\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "#get collection name from chromaDB\n",
    "#COLLECTION_NAME = \"ng12\"\n",
    "#chroma_collection = client.get_collection(name=COLLECTION_NAME)\n",
    "#embed_model = embeddings\n",
    "\n",
    "#vectore store\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"ng12\",\n",
    "    embedding_function=GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\"),\n",
    "    persist_directory=\"./chroma_db\"\n",
    ")\n",
    "\n",
    "#storage context\n",
    "#storage_context = StorageContext.from_defaults(vectorstore=vectorstore)\n",
    "#storage_context.persist()\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=\"Shortness of breath with cough or fatigue or chest pain or weight loss or appetite loss (unexplained), 40 and over: possible cancer Lung or mesothelioma\", metadata={\"referral\": \"Urgent\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"52\"}),\n",
    "    Document(page_content=\"Bleeding, bruising or petechiae, unexplained: possible cancer Leukaemia\", metadata={\"referral\": \"Very urgent\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"43\"}),\n",
    "    Document(page_content=\"Fracture unexplained, 60 and over: possible cancer Myeloma\", metadata={\"referral\": \"Unexplained\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"55\"}),\n",
    "    Document(page_content=\"Refer people using a suspected cancer pathway referral for oesophageal cancer if they: have dysphagia or, are aged 55 and over, with weight loss, and they have any of the following: upper abdominal pain, reflux, dyspepsia. [2015, amended 2025]\", metadata={\"referral\": \"Suspected cancer pathway referral\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"11\"}),\n",
    "    Document(page_content=\"Skin lesion that raises the suspicion of a basal cell carcinoma: possible cancer Basal cell carcinoma  \", metadata={\"referral\": \"Raises the suspicion of\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"58\"}),\n",
    "    Document(page_content=\"Urinary urgency or frequency, increased and persistent or frequent, particularly more than 12 times per month in women, especially if 50 and over: possible cancer Ovarian\", metadata={\"referral\": \"Persistent\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"60\"}),\n",
    "    Document(page_content=\"Upper abdominal pain with low haemoglobin levels or raised platelet count or nausea or vomiting, 55 and over: possible cancer Oesophageal or stomach \", metadata={\"referral\": \"Non-urgent\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"40\"}),\n",
    "    Document(page_content=\"Petechiae unexplained in children and young people: possible cancer Leukaemia\", metadata={\"referral\": \"Immediate\", \"source\": \"Suspected cancer: recognition and referral (NG12) 2026\", \"page\": \"74\"})\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63265b9f",
   "metadata": {},
   "source": [
    "##### Maximum Marginal Relevance:\n",
    "---\n",
    "I use my lambda (ƛ) value as a threshold:\n",
    "- 0 = Max diversity ƛ=0\n",
    "- 1 = max relevance ƛ=1\n",
    "\n",
    "**Potential Tuning for MMR:**\n",
    "- Navigational/Exact--> ƛ= 0.7 - 0.9: \"Is this patient at 403 an urgent referral?\"\n",
    "- Balanced/Research--> ƛ= 0.5 - 0.7: \"What is the best referral recommendation based on symptoms of patient403?\"\n",
    "- Exploratory/Diverse--> ƛ= 0.3 - 0.5: \"Give me a summary of findings and determine referral status..\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8c5813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create retriever from vector store and then apply MMR \n",
    "\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",\n",
    "    search_kwargs={\n",
    "        \"k\": 8,\n",
    "        \"fetch_k\": 50,\n",
    "        \"lambda_mult\": 0.6\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e741d",
   "metadata": {},
   "source": [
    "# Techniques used(for my readme):\n",
    "- vector store as retrieval\n",
    "- response enhancement\n",
    "- MMR to diversify the output response \n",
    "- Source attribution--> helps prevent hallucinations in the model to output where information comes from\n",
    "- add Maximal marginal relevance to ensure a balance of diversity and relevance retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc721263",
   "metadata": {},
   "source": [
    "# **Perform Context Engineering**\n",
    "---\n",
    "### Tradeoffs:\n",
    "\n",
    "**Why did I choose this approach for context engineering?**\n",
    "\n",
    "**Reasoning:** \n",
    "At first, my goal was to return a single string of relevant documents. However, I realized that my agent would have trouble parsing my actual data in production. Based on the way the data is formatted in retrieval, I had to make some adjustments, and go a bit deeper into context engineering. Also, one of the key constraints in building this agent included a task to cite the specific sources within the relevant data retrieved from the NG12 documents. I could have kept my single string, however, there would have been significant fine-tuning and overhead later. Performing context engineering was the only plausible to way achieve this goal. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc77bd73",
   "metadata": {},
   "source": [
    "#### Adding Clinical Context Tool\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704c5f4",
   "metadata": {},
   "source": [
    "# **STOPPING POINT BEFORE ADDING SOURCE ATTRIBUTION TO GET BETTER CONTEXT:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3fbc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for context engineering\n",
    "def get_cancer_context(docs):\n",
    "    context = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        page = doc.metatdata.get(\"page\", \"?\")\n",
    "        block = f\"[Source: Page {page}] {doc.page_content}\"\n",
    "        context.append(block)\n",
    "    return \"\\n---\\n\".join(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clinical context tooling for response -pg143\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "@tool\n",
    "def get_cancer_context(docs):\n",
    "    \"\"\"\n",
    "    Tool to extract the relevant clinial context from the retrieved documents. \n",
    "    This tool will be how we prepare the reasoning for the agent, to ensure \n",
    "    correct hybrid results for the NG12 Cancer Risk Assessor guidelines engine.\n",
    "    \"\"\"\n",
    "\n",
    "    context =[]\n",
    "    for i, doc in enumerate(docs):\n",
    "        page = doc.metadata.get(\"page\", \"Unknown Page\")\n",
    "        section = doc.metadata.get(\"section\", \"General Guidance\")\n",
    "\n",
    "        block = (\n",
    "            f\"[CLINICAL EVIDENCEM {i+1}]\\n\"\n",
    "            f\"SOURCE: NICE Guideline NG12, Page {page}, Section: {section}\\n\"\n",
    "            f\"TEXT: {doc.page_content}\\n\"\n",
    "        )\n",
    "        context.append(block)\n",
    "    return \"\\n---\\n\".join(context)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_stable312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
